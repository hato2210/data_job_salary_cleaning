{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver \n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose):\n",
    "    \n",
    "    '''Gathers jobs as a dataframe, scraped from Indeed'''\n",
    "\n",
    "    # Initializing the webdriver.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('headless') # Uncomment the left code for browserless scraping.\n",
    "    service = Service(executable_path='/Users/tonyha/Documents/Projects/salary_prediction/chromedriver')\n",
    "    driver = webdriver.Chrome(service = service, options=options)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    keyword = keyword.replace(\" \", \"+\") # Indeed requires '+' between the words in the url.\n",
    "    url = \"https://au.indeed.com/jobs?q=\"+keyword+\"&l=&from=searchOnHP&vjk=514cd2942c99e51d\"\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    jobs = [] # We store our job here. It will be a list of dictionaries. \n",
    "\n",
    "    time.sleep(4) # The waiting time (in seconds) between requests. Ensure it is high enough to load pages. \n",
    "    \n",
    "    # Before we scrape, we close the job alert popup that appears on the second page, then go back to the first page.\n",
    "    if len(driver.find_elements(By.XPATH, \"//a[@data-testid='pagination-page-next']\"))>0:\n",
    "        driver.find_element(By.XPATH, \"//a[@data-testid='pagination-page-next']\").click()\n",
    "        time.sleep(4)\n",
    "        popup_closed = False\n",
    "        while not popup_closed:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"//*[@id='mosaic-desktopserpjapopup']/div[1]/button\").click()\n",
    "                popup_closed = True\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "        driver.find_element(By.XPATH, \"//a[@data-testid='pagination-page-prev']\").click()\n",
    "\n",
    "    while len(jobs) < num_jobs:  # If true, should be still looking for new jobs.\n",
    "\n",
    "        # 'job_buttons' contains all the jobs on the current page.\n",
    "        job_buttons = driver.find_elements(By.XPATH, \"//li[@class='css-5lfssm eu4oa1w0'][not(.//div[@class='mosaic mosaic-empty-zone nonJobContent-desktop'])]\")\n",
    "\n",
    "        for job_button in job_buttons: # Going through each job on the current page.\n",
    "\n",
    "            if len(jobs) >= num_jobs: # Stop if we have collected enough jobs mid-way through the page.\n",
    "                break\n",
    "\n",
    "            job_button.click() # Click the job listing to open its contents. \n",
    "            \n",
    "            time.sleep(5)\n",
    "\n",
    "            # Collect information on the job title, location, and description. These should always be available under each job, and we make \n",
    "            # sure we obtain them by using a while loop. \n",
    "            collected_successfully = False\n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    job_title = driver.find_element(By.XPATH, \"//h2[@class='jobsearch-JobInfoHeader-title css-1t78hkx e1tiznh50']\").text.split('\\n')[0]\n",
    "                    location = driver.find_element(By.XPATH, \"//div[@data-testid='inlineHeader-companyLocation']/div\").text\n",
    "                    job_description = driver.find_element(By.XPATH, \"//div[@id='jobDescriptionText']\").text\n",
    "                    collected_successfully = True\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "\n",
    "            # Collect other useful information. If they are missing from the job listing we assign \"missing\". \n",
    "            try:\n",
    "                company_name = driver.find_element(By.XPATH, \"//span[@class='css-1saizt3 e1wnkr790']/a[@aria-label]\").text\n",
    "            except NoSuchElementException:\n",
    "                company_name = \"missing\"\n",
    "\n",
    "            try:\n",
    "                employment_type = driver.find_element(By.XPATH, \"//div[@id='salaryInfoAndJobType']/span[@class='css-k5flys eu4oa1w0']\").text\n",
    "            except NoSuchElementException:\n",
    "                employment_type = \"missing\"\n",
    "\n",
    "            try:\n",
    "                salary = driver.find_element(By.XPATH, \"//div[@id='salaryInfoAndJobType']/span[@class='css-19j1a75 eu4oa1w0']\").text\n",
    "            except NoSuchElementException:\n",
    "                salary = \"missing\"\n",
    "            \n",
    "            # To get information on the industry and company size we must click on the company name to open a new link. After scraping its \n",
    "            # contents we close the tab.\n",
    "            if company_name != \"missing\": # The link is only available if there is a company name.\n",
    "                original_window = driver.current_window_handle # Stores the main window we we can switch back to it after scraping the link.\n",
    "                assert len(driver.window_handles) == 1 # Before clicking the link, we make sure the current window is the only one.\n",
    "                driver.find_element(By.XPATH, \"//div[@data-testid='inlineHeader-companyName']\").click() # Click company name to open link.\n",
    "                wait.until(EC.number_of_windows_to_be(2)) # Wait for the new window to load.\n",
    "                driver.switch_to.window(driver.window_handles[-1]) # Switch to the new window. \n",
    "                time.sleep(5)\n",
    "                try:\n",
    "                    industry = driver.find_element(By.XPATH, \"//li[@data-testid='companyInfo-industry']/div[2]\").text\n",
    "                except:\n",
    "                    industry = \"missing\"\n",
    "                try:\n",
    "                    company_size = driver.find_element(By.XPATH, \"//li[@data-testid='companyInfo-employee']/div[2]\").text\n",
    "                except:\n",
    "                    company_size = \"missing\"\n",
    "                driver.close() # Close the tab\n",
    "                driver.switch_to.window(original_window) # Switch back to main window.\n",
    "                time.sleep(5)\n",
    "\n",
    "            # Printing for debugging\n",
    "            if verbose:\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Location: {}\".format(location))\n",
    "                print(\"Work Model: missing\")\n",
    "                print(\"Employment Type: {}\".format(employment_type))\n",
    "                print(\"Industry: {}\".format(industry))\n",
    "                print(\"Company Type: missing\")\n",
    "                print(\"Company Size: {}\".format(company_size))\n",
    "                print(\"Job Description: {}\".format(job_description[:100]))\n",
    "                print(\"Salary: {}\".format(salary))\n",
    "\n",
    "            # Add the job to 'jobs'.\n",
    "            jobs.append({\"Job Title\": job_title,\n",
    "            \"Company Name\": company_name,\n",
    "            \"Location\": location,\n",
    "            \"Work Model\": \"missing\",\n",
    "            \"Employment Type\": employment_type,\n",
    "            \"Industry\": industry,\n",
    "            \"Company Type\": \"missing\",\n",
    "            \"Company Size\": company_size,\n",
    "            \"Job Description\" : job_description,\n",
    "            \"Salary\": salary})\n",
    "\n",
    "            # Print progress.\n",
    "            print(\"Progress: {}\".format(\"\" + str(len(jobs)) + \"/\" + str(num_jobs)))\n",
    "\n",
    "        # If more jobs need to be collected then go to the next page.\n",
    "        if len(jobs)<num_jobs:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"//a[@data-testid='pagination-page-next']\").click()\n",
    "                time.sleep(5) \n",
    "            except NoSuchElementException: # This will happen when the current page is the last one.\n",
    "                print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "                break\n",
    "            \n",
    "    return pd.DataFrame(jobs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the scraping. \n",
    "df = get_jobs(\"data\", 2000, False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data_indeed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
