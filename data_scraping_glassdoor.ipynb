{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd  \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose):\n",
    "    \n",
    "    '''Gathers jobs as a dataframe, scraped from Glassdoor'''\n",
    "    \n",
    "    # Initializing the webdriver.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('headless') # Uncomment the left code for browserless scraping.\n",
    "    service = Service(executable_path='/Users/tonyha/Documents/Projects/salary_prediction/chromedriver')\n",
    "    driver = webdriver.Chrome(service = service, options=options)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    keyword = keyword.replace(\" \", \"-\") # Glassdoor requires '-' between the words in the url.\n",
    "    url = \"https://www.glassdoor.com.au/Job/\"+keyword+\"-jobs-SRCH_KO0,4.htm\"\n",
    "    driver.get(url)\n",
    "    jobs = [] # We store our job listings here. It will be a list of dictionaries. \n",
    "\n",
    "    time.sleep(4) # The waiting time (in seconds) between requests. Ensure it is high enough to load pages.\n",
    "    \n",
    "    # Close the login popup. We first make it appear by clicking on the \"Show more jobs\" button once before closing it.\n",
    "    if len(driver.find_elements(By.XPATH, \"//*[@id='left-column']/div[2]/div/button\"))>0:\n",
    "        driver.find_element(By.XPATH, \"//*[@id='left-column']/div[2]/div/button\").click()\n",
    "        time.sleep(4)\n",
    "        popup_closed = False\n",
    "        while not popup_closed:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"/html/body/div[11]/div[2]/div[2]/div[1]/div[1]/button\").click()\n",
    "                popup_closed = True\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "\n",
    "    time.sleep(4)\n",
    "\n",
    "    # Keep clicking 'show more jobs' until there is none.\n",
    "    more_jobs = len(driver.find_elements(By.XPATH, \"//*[@id='left-column']/div[2]/div/button\"))>0\n",
    "    while more_jobs:\n",
    "        driver.find_element(By.XPATH, \"//*[@id='left-column']/div[2]/div/button\").click()\n",
    "        time.sleep(4) \n",
    "        more_jobs = len(driver.find_elements(By.XPATH, \"//*[@id='left-column']/div[2]/div/button\"))>0\n",
    "\n",
    "    # \"job_buttons\" contains all the jobs on the page (or more precisely, their elements).\n",
    "    job_buttons = driver.find_elements(By.XPATH, \"//ul[@aria-label='Jobs List']/li[@data-test='jobListing']\")\n",
    "    \n",
    "    # If fewer jobs are found than what is requested, tell the user. Otherwise take the first \"num_jobs\" from the page.\n",
    "    if len(job_buttons)<num_jobs:\n",
    "        print(\"The requested number of jobs is {0} but the search found {1} jobs. The scraper will therefore return only {1} jobs.\".format(num_jobs, len(job_buttons)))\n",
    "    else:\n",
    "        job_buttons = job_buttons[:num_jobs]\n",
    "    \n",
    "    for job_button in job_buttons: # Going through each job on the page.\n",
    "\n",
    "        job_button.click() # Click the job listing to open its javascript components. Allows us to obtain valuable info under this job.\n",
    "        \n",
    "        time.sleep(4)\n",
    "        \n",
    "        # Collect information on the job title, location, and description. These should always be available under each job, and we make \n",
    "        # sure we obtain them by using a while loop. \n",
    "        collected_successfully = False\n",
    "        while not collected_successfully:\n",
    "            try:\n",
    "                job_title = driver.find_element(By.XPATH, \"//h1[@class='heading_Heading__BqX5J heading_Level1__soLZs']\").text\n",
    "                location = driver.find_element(By.XPATH, \"//div[@class='JobDetails_location__mSg5h']\").text\n",
    "                job_description = driver.find_element(By.XPATH, \"//*[@id='app-navigation']/div[4]/div[2]/div[2]/div/div[1]/section/div[2]/div[1]\").text\n",
    "                collected_successfully = True\n",
    "            except:\n",
    "                time.sleep(2)\n",
    "\n",
    "        # Collect other useful information. If they are missing from the job listing we assign \"missing\". \n",
    "        try:\n",
    "            company_name = driver.find_element(By.XPATH, \"//h4[@class='heading_Heading__BqX5J heading_Subhead__Ip1aW']\").text\n",
    "        except NoSuchElementException:\n",
    "            company_name = \"missing\"\n",
    "\n",
    "        try:\n",
    "            industry = driver.find_element(By.XPATH, \"//div[@class='JobDetails_companyOverviewGrid__3t6b4']/div[5]/div\").text\n",
    "        except:\n",
    "            industry = \"missing\"\n",
    "\n",
    "        try:\n",
    "            company_type = driver.find_element(By.XPATH, \"//div[@class='JobDetails_companyOverviewGrid__3t6b4']/div[3]/div\").text\n",
    "        except:\n",
    "            company_type = \"missing\"\n",
    "\n",
    "        try:\n",
    "            company_size = driver.find_element(By.XPATH, \"//div[@class='JobDetails_companyOverviewGrid__3t6b4']/div[1]/div\").text\n",
    "        except: \n",
    "            company_size = \"missing\"\n",
    "\n",
    "        try:\n",
    "            salary = driver.find_element(By.XPATH, \"//div[@class='SalaryEstimate_salaryRange__brHFy']\").text\n",
    "        except NoSuchElementException:\n",
    "            salary = \"missing\"\n",
    "\n",
    "        #Printing for debugging\n",
    "        if verbose:\n",
    "            print(\"Job Title: {}\".format(job_title))\n",
    "            print(\"Company Name: {}\".format(company_name))\n",
    "            print(\"Location: {}\".format(location))\n",
    "            print(\"Work Model: missing\")\n",
    "            print(\"Employment Type: missing\")\n",
    "            print(\"Industry: {}\".foramt(industry))\n",
    "            print(\"Company Type: {}\".format(company_type))\n",
    "            print(\"Company Size: {}\".format(company_size))\n",
    "            print(\"Job Description: {}\".format(job_description[:100]))\n",
    "            print(\"Salary: {}\".format(salary))\n",
    "\n",
    "        #Add the job to 'jobs'.\n",
    "        jobs.append({\"Job Title\": job_title,\n",
    "        \"Company Name\": company_name,\n",
    "        \"Location\": location,\n",
    "        \"Work Model\": \"missing\",\n",
    "        \"Employment Type\": \"Missing\",\n",
    "        \"Industry\": industry,\n",
    "        \"Company Type\": company_type,\n",
    "        \"Company Size\": company_size,\n",
    "        \"Job Description\" : job_description,\n",
    "        \"Salary\": salary})\n",
    "\n",
    "        #Print progress.\n",
    "        print(\"Progress: {}\".format(\"\" + str(len(jobs)) + \"/\" + str(len(job_buttons))))\n",
    "            \n",
    "    return pd.DataFrame(jobs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the scraping. \n",
    "df = get_jobs(\"data\", 2000, False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data_glassdoor.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
