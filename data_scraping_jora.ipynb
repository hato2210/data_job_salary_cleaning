{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd  \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose):\n",
    "    \n",
    "    '''Gathers jobs as a dataframe, scraped from Jora'''\n",
    "    \n",
    "    # Initializing the webdriver.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('headless') # Uncomment the left code for browserless scraping.\n",
    "    service = Service(executable_path='/Users/tonyha/Documents/Projects/salary_prediction/chromedriver')\n",
    "    driver = webdriver.Chrome(service = service, options=options)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    keyword = keyword.replace(\" \", \"+\") #Jora requires '+' between the words in the url.\n",
    "    url = \"https://au.jora.com/j?sp=search&trigger_source=serp&q=\"+keyword+\"&l=\"\n",
    "    driver.get(url)\n",
    "    jobs = [] # We store our jobs here.\n",
    "\n",
    "    time.sleep(4) # The waiting time (in seconds) between requests. Ensure it is high enough to load pages.\n",
    "\n",
    "    while len(jobs) < num_jobs:  # If true, should be still looking for new jobs.\n",
    "\n",
    "        # Close the job alert popup in case it appears upon entering a new page.\n",
    "        try:\n",
    "            driver.find_element(By.XPATH, \"//div[@class='dismiss']\").click()\n",
    "            time.sleep(4)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        # 'job_buttons' contains all the jobs on the page\n",
    "        job_buttons = driver.find_elements(By.XPATH, \"//div[contains(@class, 'job-card result organic-job') or contains(@class, 'job-card result sponsored-job premium-job spon-top') or contains(@class, 'job-card result sponsored-job premium-job spon-bottom')]\") \n",
    "\n",
    "        for job_button in job_buttons: # Going through each job on the page.\n",
    "\n",
    "            if len(jobs) >= num_jobs: # If we have collected enough jobs mid-way through the page then stop. \n",
    "                break\n",
    "\n",
    "            # Click the job listing to open its javascript components. Allows us to obtain valuable info under this job. Note that if we are \n",
    "            # not careful where we click, then we might inadvertantly click on a link. This will result in an error  \n",
    "            # (probably 'StaleElementReferenceException' since the next job in 'job_buttons' will not appear in the new link).\n",
    "            # We avoid this by clicking on any spot that we are certain will contain no links. Here we click on the title of the job listing. \n",
    "            # Note the '.' in the path. This is necessary since we want to start searching from the element in job_button. \n",
    "            # Withtout it, it will start searching from root, which is not what we want. \n",
    "            job_button.find_element(By.XPATH, \"./div[@class='top-container']\").click() \n",
    "            \n",
    "            time.sleep(4)\n",
    "\n",
    "            # Collect information on the job title, location, and description. These should always be available under each job, and we make \n",
    "            # sure we obtain them by using a while loop. \n",
    "            collected_successfully = False\n",
    "            while not collected_successfully:\n",
    "                try:\n",
    "                    job_title = driver.find_element(By.XPATH, \"//h3[@class='job-title heading -size-xxlarge -weight-700']\").text\n",
    "                    location = driver.find_element(By.XPATH, \"//span[@class='location']\").text\n",
    "                    job_description = driver.find_element(By.XPATH, \"//div[@class='job-description-container']\").text\n",
    "                    collected_successfully = True\n",
    "                except:\n",
    "                    time.sleep(2)\n",
    "\n",
    "            # Collect other useful information. If they are missing from the job listing we assign \"missing\". \n",
    "            try:\n",
    "                company_name = driver.find_element(By.XPATH, \"//span[@class='company']\").text\n",
    "            except NoSuchElementException:\n",
    "                company_name = \"missing\"\n",
    "\n",
    "            try:\n",
    "                employment_type = driver.find_element(By.XPATH, \"//div[@id='job-info-container']/div[@class='badge -default-badge']/div[@class='content'][not(contains(text(), '$'))]\").text\n",
    "            except NoSuchElementException:\n",
    "                employment_type = \"missing\"\n",
    "\n",
    "            try:\n",
    "                salary = driver.find_element(By.XPATH, \"//div[@id='job-info-container']/div[@class='badge -default-badge']/div[@class='content'][contains(text(), '$')]\").text\n",
    "            except NoSuchElementException:\n",
    "                salary = \"missing\"\n",
    "\n",
    "            # Printing for debugging.\n",
    "            if verbose:\n",
    "                print(\"Job Title: {}\".format(job_title))\n",
    "                print(\"Company Name: {}\".format(company_name))\n",
    "                print(\"Location: {}\".format(location))\n",
    "                print(\"Work Model: missing\")\n",
    "                print(\"Employment Type: {}\".format(employment_type))\n",
    "                print(\"Industry: missing\")\n",
    "                print(\"Company Type: missing\")\n",
    "                print(\"Company Size: missing\")\n",
    "                print(\"Job Description: {}\".format(job_description[:100]))\n",
    "                print(\"Salary: {}\".format(salary))\n",
    "\n",
    "            #Add the job to 'jobs'.\n",
    "            jobs.append({\"Job Title\": job_title,\n",
    "            \"Company Name\": company_name,\n",
    "            \"Location\": location,\n",
    "            \"Work Model\": \"missing\",\n",
    "            \"Employment Type\": employment_type,   \n",
    "            \"Industry\": \"missing\",\n",
    "            \"Company Type\": \"missing\", \n",
    "            \"Company Size\": \"missing\",\n",
    "            \"Job Description\": job_description,\n",
    "            \"Salary\": salary})\n",
    "\n",
    "            #Print progress.\n",
    "            print(\"Progress: {}\".format(\"\" + str(len(jobs)) + \"/\" + str(num_jobs)))\n",
    "\n",
    "        # If more jobs need to be collected then go to the next page.\n",
    "        if len(jobs)<num_jobs:\n",
    "            try:\n",
    "                driver.find_element(By.XPATH, \"//a[@class='next-page-button']\").click()\n",
    "                time.sleep(4)\n",
    "            except NoSuchElementException: # This will happen when the current page is the last one.\n",
    "                print(\"Scraping terminated before reaching target number of jobs. Needed {}, got {}.\".format(num_jobs, len(jobs)))\n",
    "                break\n",
    "    return pd.DataFrame(jobs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start the scraping. \n",
    "df = get_jobs(\"data\", 2000, False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data_jora.csv\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
