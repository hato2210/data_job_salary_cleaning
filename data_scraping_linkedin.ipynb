{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd  \n",
    "import time \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jobs(keyword, num_jobs, verbose):\n",
    "    \n",
    "    '''Gathers jobs as a dataframe, scraped from LinkedIn'''\n",
    "    \n",
    "    # Initializing the webdriver.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    # options.add_argument('headless') # Uncomment the left code for browserless scraping.\n",
    "    service = Service(executable_path='/Users/tonyha/Documents/Projects/salary_prediction/chromedriver')\n",
    "    driver = webdriver.Chrome(service = service, options=options)\n",
    "    driver.maximize_window()\n",
    "\n",
    "    # We start at the homepage since the site may force us to go there anyways.\n",
    "    url = \"https://www.linkedin.com/?trk=guest_homepage-basic_nav-header-logo\"\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    jobs = [] # We store our job listings here. It will be a list of dictionaries.\n",
    "\n",
    "    time.sleep(4) # The waiting time (in seconds) between requests. Ensure it is high enough to load pages. \n",
    "\n",
    "    # Click on \"Jobs\" button.\n",
    "    driver.find_elements(By.XPATH, \"//icon[@class='top-nav-link__icon flex h-3 w-3 flex-shrink-0 justify-center lazy-loaded']\")[3].click()\n",
    "    time.sleep(4)\n",
    "    \n",
    "    # Input the value in the \"keyword\" variable inside in job search box.\n",
    "    job_search_box = driver.find_element(By.XPATH, \"//input[@aria-label='Search job titles or companies']\")\n",
    "    job_search_box.send_keys(keyword)\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Clear the location search box and input \"Australia\" then hit enter.\n",
    "    location_search_box = driver.find_element(By.XPATH, \"//input[@aria-label='Location']\")\n",
    "    location_search_box.clear()\n",
    "    time.sleep(3)\n",
    "    location_search_box.send_keys(\"Australia\")\n",
    "    time.sleep(3)\n",
    "    location_search_box.send_keys(Keys.ENTER)\n",
    "    time.sleep(4) \n",
    "\n",
    "    # Scroll to the bottom of the page until it no longer loads.\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\") # Get current height of page.\n",
    "    body = driver.find_element(By.XPATH, \"/html/body\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\") # Scroll to the bottom to load.\n",
    "        time.sleep(2)\n",
    "        body.send_keys(Keys.ARROW_UP) # To help the page load.\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height: # Only possible when the page no longer loads, i.e., we have reached the end.\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Click \"See more jobs\". Sometimes when clicking the button the page does not load. If this happens above a threshold then we stop clicking. \n",
    "    fail_threshold = 10 # Number of fail clicks allowed before stopping. \n",
    "    fail_count = 0 # Count the number of failed clicks.\n",
    "    more_jobs = len(driver.find_elements(By.XPATH, \"//button[@aria-label='See more jobs']\"))>0 # Determine if the button exists.\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\") # Get current height of page.\n",
    "    while more_jobs and fail_count<fail_threshold: # While the button exists and we are below the fail threshold.\n",
    "        driver.find_element(By.XPATH, \"//button[@aria-label='See more jobs']\").click() # Click the button.\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        # We determine whether clicking the button loads the page or not by the height of the page. If the height stays the same then \n",
    "        # it means that it did not load. In this case we increase the fail count by 1.\n",
    "        if new_height == last_height: \n",
    "            fail_count += 1\n",
    "        else: # The click is successful and the page loads. We reset the fail count. \n",
    "            fail_count = 0\n",
    "            last_height = new_height\n",
    "            # Check if the button still exists after loading. Note that the below code is not required if the loading fails, since the button\n",
    "            # will still be there.\n",
    "            more_jobs = len(driver.find_elements(By.XPATH, \"//button[@aria-label='See more jobs']\"))>0 \n",
    "\n",
    "    time.sleep(4)\n",
    "\n",
    "    # 'job_buttons' contains all the jobs on the page.\n",
    "    job_buttons = driver.find_elements(By.XPATH, \"//ul[@class='jobs-search__results-list']/*\")\n",
    "    \n",
    "    # If fewer jobs are found than what is requested, tell the user. Otherwise take the first \"num_jobs\" from the page.\n",
    "    if len(job_buttons)<num_jobs:\n",
    "        print(\"The requested number of jobs is {0} but the search found {1} jobs. The scraper will therefore return only {1} jobs.\".format(num_jobs, len(job_buttons)))\n",
    "    else:\n",
    "        job_buttons = job_buttons[:num_jobs]\n",
    "    \n",
    "    for job_counter in range(len(job_buttons)): # Going through each job on the page.\n",
    "\n",
    "        job_buttons[job_counter].click() # Click the job listing to open its contents. \n",
    "        \n",
    "        time.sleep(4)\n",
    "\n",
    "        # Sometimes clicking on a job does not load it. One fix is to click on a different job, then click the current job again. The \n",
    "        # \"different\" job depends on whether the job that does not load is the first one or not. We implement this idea in the following way. \n",
    "        # If the first job does not load then click on the previous one, for every other job click on the next one. Finally, to check\n",
    "        # if a page has loaded or not, we see whether the job title text is empty. \n",
    "        job_clicked_successfuly = len(driver.find_element(By.XPATH, \"//span[@class='topcard__flavor topcard__flavor--bullet']\").text)>0\n",
    "        while not job_clicked_successfuly:\n",
    "            if job_counter == 0:\n",
    "                job_buttons[job_counter+1].click()\n",
    "                time.sleep(2)\n",
    "                job_buttons[job_counter].click()\n",
    "                time.sleep(4)\n",
    "                job_clicked_successfuly = len(driver.find_element(By.XPATH, \"//span[@class='topcard__flavor topcard__flavor--bullet']\").text)>0\n",
    "            else:\n",
    "                job_buttons[job_counter-1].click()\n",
    "                time.sleep(2)\n",
    "                job_buttons[job_counter].click()\n",
    "                time.sleep(4)\n",
    "                job_clicked_successfuly = len(driver.find_element(By.XPATH, \"//span[@class='topcard__flavor topcard__flavor--bullet']\").text)>0\n",
    "    \n",
    "        # Collect information on the job title, location, and description. These should always be available under each job.\n",
    "        job_title = driver.find_element(By.XPATH, \"//h2[@class='top-card-layout__title font-sans text-lg papabear:text-xl font-bold leading-open text-color-text mb-0 topcard__title']\").text\n",
    "        location = driver.find_element(By.XPATH, \"//span[@class='topcard__flavor topcard__flavor--bullet']\").text\n",
    "        job_description = driver.find_element(By.XPATH, \"//div[@class='description__text description__text--rich']/section/div\").text\n",
    "\n",
    "        # Colelct information on the company name, employment type, and job salary. If they are missing from the job listing we assign \"missing\".\n",
    "        try:\n",
    "            company_name = driver.find_element(By.XPATH, \"//a[@class='topcard__org-name-link topcard__flavor--black-link']\").text\n",
    "        except NoSuchElementException:\n",
    "            company_name = \"missing\"\n",
    "\n",
    "        try:\n",
    "            employment_type = driver.find_element(By.XPATH, \"//ul[@class='description__job-criteria-list']/li[2]/span[@class='description__job-criteria-text description__job-criteria-text--criteria']\").text\n",
    "        except NoSuchElementException:\n",
    "            employment_type = 'missing'\n",
    "\n",
    "        try:\n",
    "            salary = driver.find_element(By.XPATH, \"//div[@class='salary compensation__salary']\").text\n",
    "        except NoSuchElementException:\n",
    "            salary = 'missing'\n",
    "\n",
    "        # To get information on the industry, company type, and company size we must click on the company name to open a new link. After scraping its \n",
    "        # contents we close the tab.\n",
    "        if company_name != \"missing\": # The link is only available if there is a company name.\n",
    "            original_window = driver.current_window_handle # Stores the main window so we can switch back to it after scraping the link.\n",
    "            assert len(driver.window_handles) == 1 # Before clicking the link we make sure the current window is the only one.\n",
    "            driver.find_element(By.XPATH, \"//a[@class='topcard__org-name-link topcard__flavor--black-link']\").click() # Click company name to open the link.\n",
    "            wait.until(EC.number_of_windows_to_be(2)) # Wait for the new window to load.\n",
    "            driver.switch_to.window(driver.window_handles[-1]) # Switch to the new window. \n",
    "            time.sleep(4)\n",
    "            try: # Close the sign-in popup if it appears.\n",
    "                driver.find_element(By.XPATH, \"//icon[@class='contextual-sign-in-modal__modal-dismiss-icon lazy-loaded']\").click()\n",
    "                time.sleep(4)\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                industry = driver.find_element(By.XPATH, \"//div[@class='core-section-container__content break-words']/dl/div[@data-test-id='about-us__industry']/dd\").text\n",
    "            except:\n",
    "                industry = \"missing\"\n",
    "            try:\n",
    "                company_type = driver.find_element(By.XPATH, \"//div[@class='core-section-container__content break-words']/dl/div[@data-test-id='about-us__organizationType']/dd\").text\n",
    "            except:\n",
    "                company_type = \"missing\"\n",
    "            try:\n",
    "                company_size = driver.find_element(By.XPATH, \"//div[@class='core-section-container__content break-words']/dl/div[@data-test-id='about-us__size']/dd\").text\n",
    "            except:\n",
    "                company_size = \"missing\"\n",
    "            driver.close() # Close the tab\n",
    "            driver.switch_to.window(original_window) # Switch back to main window.\n",
    "            time.sleep(4)\n",
    "\n",
    "        # Printing for debugging.\n",
    "        if verbose:\n",
    "            print(\"Job Title: {}\".format(job_title))\n",
    "            print(\"Company Name: {}\".format(company_name))\n",
    "            print(\"Location: {}\".format(location))\n",
    "            print(\"Work Model: missing\")\n",
    "            print(\"Employment Type: {}\".format(employment_type))\n",
    "            print(\"Industry: {}\".format(industry))\n",
    "            print(\"Company Type: {}\".format(company_type))\n",
    "            print(\"Company Size: {}\".format(company_size))\n",
    "            print(\"Job Description: {}\".format(job_description[:100]))\n",
    "            print(\"Salary: {}\".format(salary))\n",
    "            \n",
    "        # Add the job to 'jobs'.\n",
    "        jobs.append({\"Job Title\": job_title,\n",
    "        \"Company Name\": company_name,\n",
    "        \"Location\": location,\n",
    "        \"Work Model\": \"missing\",\n",
    "        \"Employment Type\": employment_type,\n",
    "        \"Industry\": industry,\n",
    "        \"Company Type\": company_type,\n",
    "        \"Company Size\": company_size,\n",
    "        \"Job Description\" : job_description,\n",
    "        \"Salary\": salary})\n",
    "\n",
    "        # Print progress.\n",
    "        print(\"Progress: {}\".format(\"\" + str(len(jobs)) + \"/\" + str(len(job_buttons))))\n",
    "        \n",
    "    return pd.DataFrame(jobs) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the scraping. \n",
    "df = get_jobs(\"data\", 2000, False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"data_linkedin.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
